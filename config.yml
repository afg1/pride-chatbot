llm:
    chatglm: /hps/nobackup/juan/pride/chatbot/pride-chatbot/models/THUDM/chatglm-6b/
    chatglm2: /hps/nobackup/juan/pride/chatbot/pride-chatbot/models/THUDM/chatglm2-6b/
    #change the following directory according the environment of EBI server
    GPT4ALL_PATH: /hps/nobackup/juan/pride/chatbot/pride-chatbot/models/THUDM/autodl-tmp/
    GPTEALL_MODEL: ggml-gpt4all-j-v1.3-groovy.bin
    Vicuna-13B: /hps/nobackup/juan/pride/chatbot/pride-chatbot/models/THUDM/vicuna-13b-v1.3/
    mbt-7b-chat: /hps/nobackup/juan/pride/chatbot/pride-chatbot/models/THUDM/mpt-7b-chat/
    guanaco-7b: /hps/nobackup/juan/pride/chatbot/pride-chatbot/models/THUDM/guanaco-7b/
    llama-7b: /hps/nobackup/juan/pride/chatbot/pride-chatbot/models/THUDM/llama-7b/
    llama2-7b-chat: /hps/nobackup/juan/pride/chatbot/pride-chatbot/models/THUDM/Llama-2-7b-chat-hf/
    gpu: True
    embedding: all-MiniLM-L6-v2
    model_type: bert
vector:
    uui: d4a1cccb-a9ae-43d1-8f1f-9919c90ad369
    #uui: backup_embedding
    chunk_size: 500
    chunk_overlap: 50
    api_store: ./vector_store/
    cli_store: ./vector/
